{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aba96f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\xogus\\Downloads\\bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 50.4ms\n",
      "Speed: 4.9ms preprocess, 50.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# 사전 학습된 모델 로드\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# 이미지에 대해 객체 감지\n",
    "results = model('C:/Users/xogus/Downloads/bus.jpg', device='cpu')\n",
    "\n",
    "# 결과 시각화\n",
    "results[0].show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ff703de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: tensor([[0.6523, 0.0249, 0.3228]], device='cuda:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "import clip\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "text = clip.tokenize([\"a dog\", \"a candle\", \"a car\"]).to(device)\n",
    "image = torch.randn(1, 3, 224, 224).to(device)  # 테스트용 더미 이미지\n",
    "\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text)\n",
    "    similarity = (image_features @ text_features.T).softmax(dim=-1)\n",
    "\n",
    "print(\"Similarity:\", similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dac60ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# YOLOv8 모델 로드\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# 웹캠 열기 (0번 카메라)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 객체 인식 수행 (CPU 사용)\n",
    "    results = model(frame, device='cpu')\n",
    "\n",
    "    # 결과 이미지 생성\n",
    "    annotated_frame = results[0].plot()\n",
    "\n",
    "    # 가장 높은 확률의 객체명 추출\n",
    "    boxes = results[0].boxes\n",
    "    if boxes and len(boxes.cls) > 0:\n",
    "        class_id = int(boxes.cls[0])\n",
    "        class_name = model.names[class_id]\n",
    "        print(\"Top-1 Object:\", class_name)\n",
    "\n",
    "    # 화면 출력\n",
    "    cv2.imshow(\"YOLOv8 Detection\", annotated_frame)\n",
    "\n",
    "    # 'q' 키 누르면 종료\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9185a079",
   "metadata": {},
   "source": [
    "다음 단계는 3단계: CLIP을 활용한 객체명 → 음악 태그 유사도 계산이야. 지금까지 실시간 객체 인식이 되니까, 이제 인식된 객체명을 CLIP 텍스트 인코더에 넣고, 사전에 정의한 음악 태그들과의 의미 유사도를 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae1f1bf",
   "metadata": {},
   "source": [
    "3단계: CLIP 기반 의미 유사도 계산\n",
    "목표\n",
    "YOLO에서 인식된 객체명 → CLIP 텍스트 임베딩\n",
    "\n",
    "음악 태그 리스트 → CLIP 텍스트 임베딩\n",
    "\n",
    "두 임베딩 사이 코사인 유사도 계산\n",
    "\n",
    "가장 유사한 Top-N 태그 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7efcefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object: candle\n",
      "Top-3 tags: ['romantic', 'dreamy', 'freedom']\n"
     ]
    }
   ],
   "source": [
    "import clip\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 장치 설정\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# CLIP 모델 로드\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# 예시 객체명\n",
    "object_name = \"candle\"\n",
    "\n",
    "# 예시 음악 태그 리스트\n",
    "music_tags = [\"romantic\", \"hip-hop\", \"sad\", \"freedom\", \"jazz\", \"lofi\", \"party\", \"dreamy\"]\n",
    "\n",
    "# 객체명 + 태그 리스트 토크나이징\n",
    "texts = [f\"a {object_name}\"] + music_tags\n",
    "text_tokens = clip.tokenize(texts).to(device)\n",
    "\n",
    "# 텍스트 임베딩\n",
    "with torch.no_grad():\n",
    "    text_features = model.encode_text(text_tokens)\n",
    "\n",
    "# 객체 벡터와 태그 벡터 분리\n",
    "object_vec = text_features[0].unsqueeze(0)  # shape: (1, 512)\n",
    "tag_vecs = text_features[1:]               # shape: (N, 512)\n",
    "\n",
    "# 유사도 계산\n",
    "similarities = cosine_similarity(object_vec.cpu(), tag_vecs.cpu()).flatten()\n",
    "\n",
    "# Top-N 유사도 높은 태그 추출\n",
    "top_n = 3\n",
    "top_indices = similarities.argsort()[::-1][:top_n]\n",
    "top_tags = [music_tags[i] for i in top_indices]\n",
    "\n",
    "# 출력\n",
    "print(f\"Object: {object_name}\")\n",
    "print(f\"Top-{top_n} tags: {top_tags}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a5fb25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'q' to quit.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import clip\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# CLIP 장치 설정\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# YOLOv8 모델 로드\n",
    "yolo_model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# 음악 태그 리스트 (확장 가능)\n",
    "music_tags = [\"romantic\", \"hip-hop\", \"sad\", \"freedom\", \"jazz\", \"lofi\", \"party\", \"dreamy\"]\n",
    "\n",
    "# 태그 벡터 미리 계산\n",
    "tag_tokens = clip.tokenize(music_tags).to(device)\n",
    "with torch.no_grad():\n",
    "    tag_vecs = clip_model.encode_text(tag_tokens)\n",
    "\n",
    "# 웹캠 열기\n",
    "cap = cv2.VideoCapture(0)  # 0번 카메라\n",
    "\n",
    "print(\"Press 'q' to quit.\")\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 객체 탐지 (YOLOv8)\n",
    "    results = yolo_model(frame, device='cpu')\n",
    "    annotated_frame = results[0].plot()\n",
    "\n",
    "    # 가장 확률 높은 객체명 가져오기\n",
    "    boxes = results[0].boxes\n",
    "    if boxes and len(boxes.cls) > 0:\n",
    "        class_id = int(boxes.cls[0])\n",
    "        class_name = yolo_model.names[class_id]\n",
    "        print(f\"Detected Object: {class_name}\")\n",
    "\n",
    "        # CLIP 텍스트 유사도 계산\n",
    "        texts = [f\"a {class_name}\"] + music_tags\n",
    "        text_tokens = clip.tokenize(texts).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            text_features = clip_model.encode_text(text_tokens)\n",
    "\n",
    "        object_vec = text_features[0].unsqueeze(0)\n",
    "        similarities = cosine_similarity(object_vec.cpu(), tag_vecs.cpu()).flatten()\n",
    "\n",
    "        top_n = 3\n",
    "        top_indices = similarities.argsort()[::-1][:top_n]\n",
    "        top_tags = [music_tags[i] for i in top_indices]\n",
    "\n",
    "        print(f\"Top-{top_n} Music Tags for '{class_name}': {top_tags}\")\n",
    "        cv2.putText(annotated_frame, f\"Tags: {', '.join(top_tags)}\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "    # 화면에 결과 출력\n",
    "    cv2.imshow(\"Real-Time Music Tag Recommender\", annotated_frame)\n",
    "\n",
    "    # 'q' 누르면 종료\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2ad44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ 카메라 열기 실패\n",
      "❌ 프레임 읽기 실패\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "cap = cv2.VideoCapture(0)  # 다른 장치면 1 or 2\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"❌ 카메라 열기 실패\")\n",
    "    exit()\n",
    "\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"❌ 프레임 읽기 실패\")\n",
    "        break\n",
    "\n",
    "    results = model(frame, device='cpu')\n",
    "    annotated_frame = results[0].plot()\n",
    "    cv2.imshow(\"YOLO Webcam\", annotated_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0543315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ 사용 불가: 카메라 0번\n",
      "❌ 사용 불가: 카메라 1번\n",
      "❌ 사용 불가: 카메라 2번\n",
      "❌ 사용 불가: 카메라 3번\n",
      "❌ 사용 불가: 카메라 4번\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "for i in range(5):\n",
    "    cap = cv2.VideoCapture(i)\n",
    "    if cap.isOpened():\n",
    "        print(f\"✅ 사용 가능: 카메라 {i}번\")\n",
    "        cap.release()\n",
    "    else:\n",
    "        print(f\"❌ 사용 불가: 카메라 {i}번\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97f651a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100곡 중 원하는 JSON 포맷으로 재구성\n",
    "formatted_json_output = [\n",
    "    {\n",
    "        \"spotify_id\": song.get(\"spotify_id\", \"\"),\n",
    "        \"title\": song[\"title\"],\n",
    "        \"album_name\": song.get(\"album_name\", \"\"),\n",
    "        \"release_date\": song.get(\"release_date\", \"\"),\n",
    "        \"duration\": song.get(\"duration\", \"\"),\n",
    "        \"artist\": song[\"artist\"],\n",
    "        \"genres\": song.get(\"genres\", [])\n",
    "    }\n",
    "    for song in top_100_korean_songs\n",
    "    if (song[\"title\"], song[\"artist\"]) in [(s[\"title\"], s[\"artist\"]) for s in diverse_top_100]\n",
    "]\n",
    "\n",
    "# 저장\n",
    "output_path = \"/mnt/data/top_100_korean_songs_diverse.json\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(formatted_json_output, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "output_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
